{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_framework\n",
    "import os\n",
    "import tempfile\n",
    "from google.cloud import storage, bigquery\n",
    "import pandas as pd\n",
    "\n",
    "@functions_framework.http\n",
    "def process_and_save_to_bq(request):\n",
    "    try:\n",
    "        # Configuración\n",
    "        bucket_name = \"prueba_jd_01\"\n",
    "        #source_folder_name = \"Google/metadata-sitios\"\n",
    "        destination_folder_name = \"Clean_data\"\n",
    "        project_id = \"prueba-406313\"\n",
    "        dataset_id = \"prueba-406313.DB_Google_Yelp\"\n",
    "        table_id = \"prueba-406313.DB_Google_Yelp.Restaurantes_Google\"\n",
    "\n",
    "        storage_client = storage.Client()\n",
    "        bq_client = bigquery.Client()\n",
    "\n",
    "        # Listar los objetos\n",
    "        blobs = storage_client.get_bucket(bucket_name).list_blobs()#prefix=source_folder_name)\n",
    "\n",
    "        for blob in blobs:\n",
    "            if blob.name.endswith(\".parquet\"):\n",
    "                # Descargar archivo Parquet\n",
    "                temp_dir = tempfile.mkdtemp()\n",
    "                local_file_path = os.path.join(temp_dir, os.path.basename(blob.name))\n",
    "                blob.download_to_filename(local_file_path)\n",
    "\n",
    "                # Cargar DataFrame desde archivo Parquet\n",
    "                df = pd.read_parquet(local_file_path)\n",
    "\n",
    "                # Realizar modificaciones en el DataFrame (eliminar nulos y duplicados, por ejemplo)\n",
    "                df = df.dropna().drop_duplicates()\n",
    "\n",
    "                # Subir el archivo Parquet modificado de vuelta al bucket\n",
    "                #destination_blob_name = os.path.join(destination_folder_name, os.path.basename(blob.name))\n",
    "                #destination_blob = storage_client.get_bucket(bucket_name).blob(destination_blob_name)\n",
    "                #destination_blob.upload_from_filename(local_file_path)\n",
    "\n",
    "                # Cargar el DataFrame modificado a BigQuery\n",
    "                #dataset_ref = bq_client.dataset(dataset_id)\n",
    "                #table_ref = dataset_ref.table(table_id)\n",
    "                job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "                  #  source_format=bigquery.SourceFormat.PARQUET,\n",
    "                #)\n",
    "                #with open(local_file_path, \"rb\") as source_file:\n",
    "                   # job = bq_client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "                #job.result()\n",
    "\n",
    "                df.to_gbq(destination_table=table_id, project_id=project_id, if_exists='replace', table_config=job_config)\n",
    "                # Limpiar Directorio temporal\n",
    "                os.remove(local_file_path)\n",
    "                os.rmdir(temp_dir)\n",
    "\n",
    "        return f\"Tabla {table_id} actualizada en BigQuery\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_framework\n",
    "import os\n",
    "import tempfile\n",
    "from google.cloud import storage, bigquery\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "\n",
    "@functions_framework.http\n",
    "def process_and_save_to_bq(request):\n",
    "    try:\n",
    "        # Configuración\n",
    "        bucket_name = \"prueba_jd_01\"\n",
    "        project_id = \"prueba-406313\"\n",
    "        #dataset_id = \"prueba-406313.DB_Google_Yelp\"\n",
    "        table_id = \"prueba-406313.DB_Google_Yelp.Restaurantes_Google\"\n",
    "\n",
    "        storage_client = storage.Client()\n",
    "        bq_client = bigquery.Client()\n",
    "\n",
    "        # Listar los objetos\n",
    "        blobs = storage_client.get_bucket(bucket_name).list_blobs()#prefix=source_folder_name)\n",
    "\n",
    "        for blob in blobs:\n",
    "            if blob.name.endswith(\".parquet\"):\n",
    "                # Descargar archivo Parquet\n",
    "                temp_dir = tempfile.mkdtemp()\n",
    "                local_file_path = os.path.join(temp_dir, os.path.basename(blob.name))\n",
    "                blob.download_to_filename(local_file_path)\n",
    "\n",
    "                # Cargar DataFrame desde archivo Parquet\n",
    "                df = pd.read_parquet(local_file_path)\n",
    "\n",
    "                # Realizar modificaciones en el DataFrame (eliminar nulos y duplicados, por ejemplo)\n",
    "                df = df.dropna().drop_duplicates()\n",
    "                \n",
    "                # Cargar el DataFrame modificado a BigQuery\n",
    "                #dataset_ref = bq_client.dataset(dataset_id)\n",
    "                #table_ref = dataset_ref.table(table_id)\n",
    "                job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "                \n",
    "                df.to_gbq(destination_table=table_id, project_id=project_id, if_exists='append', table_config=job_config)\n",
    "                # Limpiar Directorio temporal\n",
    "                os.remove(local_file_path)\n",
    "                os.rmdir(temp_dir)\n",
    "\n",
    "        return f\"Tabla {table_id} actualizada en BigQuery\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_framework\n",
    "import pandas as pd\n",
    "from pandas.io import gbq\n",
    "from google.cloud import storage, bigquery\n",
    "\n",
    "@functions_framework.cloud_event\n",
    "def etl_google_res(cloud_event):\n",
    "    \"\"\"Triggered by a change to a Cloud Storage bucket.\n",
    "    Args:\n",
    "    event (dict): Event payload.\n",
    "    context (google.cloud.functions.Context): Metadata for the event.\n",
    "    \"\"\"\n",
    "    event = cloud_event.data\n",
    "    lst = []\n",
    "    file_name = event['name']\n",
    "    table_name = file_name.split('.')[0]\n",
    "    project_id = \"prueba-406313\"\n",
    "    dataset_id = \"prueba-406313.DB_Google_Yelp.\"\n",
    "\n",
    "    # Event,File metadata details writing into Big Query\n",
    "    dct={\n",
    "    'Event_ID':cloud_event[\"id\"],\n",
    "    'Event_type':cloud_event[\"type\"],\n",
    "    'Bucket_name':event['bucket'],\n",
    "    'File_name':event['name'],\n",
    "    'Created':event['timeCreated'],\n",
    "    'Updated':event['updated']\n",
    "     }\n",
    "    lst.append(dct)\n",
    "    df_metadata = pd.DataFrame.from_records(lst)\n",
    "    df_metadata.to_gbq(dataset_id+'Google_restaurants_metadata', \n",
    "                    project_id=project_id, \n",
    "                    if_exists='C')\n",
    "\n",
    "     # Actual file data , writing to Big Query\n",
    "    df_data = pd.read_parquet('gs://' + event['bucket'] + '/' + file_name)\n",
    "\n",
    "    df_data = df_data.drop(columns=\"avg_rating\")\n",
    "\n",
    "    df_data.to_gbq(dataset_id + table_name, \n",
    "                    project_id=project_id, \n",
    "                    if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UBp0zWyH60Hmw6Fsasei7w</td>\n",
       "      <td>4Uh27DgGzsp6PqrH913giQ</td>\n",
       "      <td>otQS34_MymijPTdNBoBdCw</td>\n",
       "      <td>4</td>\n",
       "      <td>The bun makes the Sonoran Dog. It's like a snu...</td>\n",
       "      <td>2011-10-27 17:12:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jlvaJo1I56NrZ1Q1CUuuRw</td>\n",
       "      <td>17jzGkFYCvB5Q0fjJEzVAA</td>\n",
       "      <td>otQS34_MymijPTdNBoBdCw</td>\n",
       "      <td>4</td>\n",
       "      <td>I was told this place is a must for a Sonoran ...</td>\n",
       "      <td>2017-06-17 17:17:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yx1IGiMSFDeuosuoRE1gpQ</td>\n",
       "      <td>EYg-VaZlk13-blZxyohLDg</td>\n",
       "      <td>JUlsvVAvZvGHWFfkKm0nlg</td>\n",
       "      <td>3</td>\n",
       "      <td>We went to this restaurant after running in th...</td>\n",
       "      <td>2010-11-23 13:45:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7ouwt0DtmhHxjQpDwDkN7Q</td>\n",
       "      <td>dme9K6sQrgpojAay5r8IAA</td>\n",
       "      <td>JUlsvVAvZvGHWFfkKm0nlg</td>\n",
       "      <td>3</td>\n",
       "      <td>I loves me some seitan, and that's why I keep ...</td>\n",
       "      <td>2010-03-12 23:41:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7ym4hsISxBUwa3ugL7cL9Q</td>\n",
       "      <td>SEPSy_TUicGdTg-_72aOmQ</td>\n",
       "      <td>IwqFmo-RJs15WvA8PVHFnA</td>\n",
       "      <td>5</td>\n",
       "      <td>This place just opened up near rivers edge apa...</td>\n",
       "      <td>2018-05-19 15:04:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  UBp0zWyH60Hmw6Fsasei7w  4Uh27DgGzsp6PqrH913giQ  otQS34_MymijPTdNBoBdCw   \n",
       "1  jlvaJo1I56NrZ1Q1CUuuRw  17jzGkFYCvB5Q0fjJEzVAA  otQS34_MymijPTdNBoBdCw   \n",
       "2  yx1IGiMSFDeuosuoRE1gpQ  EYg-VaZlk13-blZxyohLDg  JUlsvVAvZvGHWFfkKm0nlg   \n",
       "3  7ouwt0DtmhHxjQpDwDkN7Q  dme9K6sQrgpojAay5r8IAA  JUlsvVAvZvGHWFfkKm0nlg   \n",
       "4  7ym4hsISxBUwa3ugL7cL9Q  SEPSy_TUicGdTg-_72aOmQ  IwqFmo-RJs15WvA8PVHFnA   \n",
       "\n",
       "   stars                                               text  \\\n",
       "0      4  The bun makes the Sonoran Dog. It's like a snu...   \n",
       "1      4  I was told this place is a must for a Sonoran ...   \n",
       "2      3  We went to this restaurant after running in th...   \n",
       "3      3  I loves me some seitan, and that's why I keep ...   \n",
       "4      5  This place just opened up near rivers edge apa...   \n",
       "\n",
       "                 date  \n",
       "0 2011-10-27 17:12:05  \n",
       "1 2017-06-17 17:17:29  \n",
       "2 2010-11-23 13:45:24  \n",
       "3 2010-03-12 23:41:38  \n",
       "4 2018-05-19 15:04:56  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"Data/yelp_latin_reviews.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14539 entries, 0 to 14538\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   review_id    14539 non-null  object        \n",
      " 1   user_id      14539 non-null  object        \n",
      " 2   business_id  14539 non-null  object        \n",
      " 3   stars        14539 non-null  int64         \n",
      " 4   text         14539 non-null  object        \n",
      " 5   date         14539 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 681.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
